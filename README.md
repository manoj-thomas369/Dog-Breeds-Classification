# ğŸ¶ DOG BREED CLASSIFICATION USING ENSEMBLE TRANSFER LEARNING

## ğŸ† OVERVIEW  
This project classifies dog breeds using an **ensemble of pretrained CNNs** â€” combining the strengths of multiple architectures to boost performance.  
The final model leverages **InceptionV3**, **Xception**, **NASNetLarge**, and **InceptionResNetV2** for feature extraction, and a custom classifier for final prediction.

---

## ğŸ“‚ DATASET  
ğŸ“¸ A labeled dataset of dog images covering various breeds.

### ğŸ” Preprocessing & Augmentation  
- **Image Resizing** â€“ Standardized input dimensions  
- **Normalization** â€“ Scaled pixel values to [0, 1]  
- **Data Augmentation** â€“ Applied flipping, rotation, zoom, and shifting  
- **Label Encoding** â€“ Converted labels into one-hot format

---

## âš™ï¸ MODEL ARCHITECTURE

### ğŸ”´ ENSEMBLE MODEL (FINAL ARCHITECTURE)  
**Feature Extractors Used:**  
- âœ… InceptionV3  
- âœ… Xception  
- âœ… NASNetLarge  
- âœ… InceptionResNetV2

**Pipeline Overview:**  
- Images passed through each pretrained model (with weights frozen)  
- Extracted feature vectors from each model  
- Concatenated features into a single vector  
- Fully connected classifier trained on combined features

ğŸ“Œ **Note:** All pretrained models were used **only for feature extraction**. No fine-tuning was applied due to computational constraints.

---

## ğŸ“Š PERFORMANCE SUMMARY

- ğŸ¯ **Training Accuracy:** 97.64%  
- ğŸ¯ **Test Accuracy:** 88.54%  
- ğŸ“‰ **Train Loss:** 1.4568  

ğŸ“Œ **Observation:**  
- High initial accuracy even without fine-tuning  
- Stable performance across different dog breeds  
- Minor overfitting expected due to model complexity and limited data  

---

## âœ… FINAL RECOMMENDATION

âœ”ï¸ **Use the ensemble model** combining *InceptionV3, Xception, NASNetLarge, and InceptionResNetV2* for the best results.  
âœ”ï¸ Use pretrained models **only for feature extraction** (freeze their weights).  
âœ”ï¸ Train **only the classifier layers** to save computation.  
âœ”ï¸ If the ensemble is too heavy, consider using a lighter model like **MobileNetV2** or **EfficientNetB0**.

---

## â— CHALLENGES FACED

ğŸ”¸ **High Dimensionality**  
- Feature fusion from models like NASNetLarge (4032-dim) creates massive input vectors  
- Leads to long training time and overfitting risk  

ğŸ”¸ **Computational Complexity**  
- Ensemble of deep models requires significant memory and compute  
- Slower predictions compared to single-model setups  

ğŸ”¸ **Difficult Error Diagnosis**  
- With multiple feature sources, itâ€™s harder to interpret misclassifications  
- Limits explainability and debugging

---

## ğŸ“‰ VISUALIZATIONS

- ğŸ“ˆ Training vs Validation Accuracy & Loss  
- ğŸ“Š Confusion Matrix  
- ğŸ“ Classification Report (Precision, Recall, F1-Score)  

---

## ğŸ›  TECH STACK

- Python  
- TensorFlow / Keras  
- OpenCV  
- NumPy, Pandas  
- Matplotlib, Seaborn  

---

## ğŸš€ FUTURE WORK

- Try dimensionality reduction (PCA, Autoencoders) before classification  
- Optimize ensemble by pruning redundant branches  
- Integrate Grad-CAM for model interpretability  
- Deploy model via Streamlit or Flask as a web application  

---

## ğŸ“ LICENSE  
This project is licensed under the **MIT License**.

---

## ğŸ™Œ CREDITS  
- TensorFlow Hub & Keras Applications  
- Public dog breed datasets  
- Researchers behind pretrained CNN architectures
